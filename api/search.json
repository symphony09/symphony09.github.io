[{"id":"603edc745edac1f578da82734f79ee53","title":"Coroutines for Go -1","content":"\n\n\n\n\n\n\n\n\n这篇文章翻译自 Go 团队主要成员 Russ Cox的协程提案research!rsc: Coroutines for Go (swtch.com)，此协程 coroutines 非彼协程 goroutine，由于全文较长，预计分为两篇，这篇主要说明是什么和为什么。本文采用AI辅助翻译，不妥之处，欢迎指正。\n本文讲述了为什么我们需要一个 Go 协程包，以及它将成为什么样子。但首先，什么是协程？\n今天的程序员都非常熟悉函数调用（子程序）：F 调用 G，F 暂停，G 运行。G 完成其工作，可能调用并等待其他函数，然 后返回。当 G 返回时，G 消失，F 继续运行。在这种模式下，只有一个函数在运行，而其调用者等待，整个调用栈都是如此。\n与子程序不同，协程在不同的栈上并发运行，但仍然只有一个协程在运行，同时其调用者等待。F 开始 G，但 G 不立即运行。相反，F 必须显式地恢复 （resume）G，然后 G 才能运行。在任何时候，G 都可以反过来通过 yield 回到 F，这会暂停 G，然后继续 F 。最终 F 再次调用 resume，这会暂停 F，然后继续 G。他们继续反复运行，直到 G 返回，这会清理 G，并从其最近的恢复操作继续 F，并给 F 发出信号，表明 G 已完成，F 应不再尝试重新启动 G。在这种模式下，只有一个协程在运行，而其调用者在不同的栈上等待。他们以一种定义明确、协调的方式轮流运行。\n这有点抽象。让我们看一些实际的程序。\nLua中的协程要使用一个著名的示例，我们可以考虑比较两个二叉树，看它们是否具有相同的值序列，即使它们的结构不同。例如，以下 是使用Lua 5编写的生成一些二叉树的代码：\nfunction T(l, v, r)\n    return &#123;left &#x3D; l, value &#x3D; v, right &#x3D; r&#125;\nend\n\ne &#x3D; nil\nt1 &#x3D; T(T(T(e, 1, e), 2, T(e, 3, e)), 4, T(e, 5, e))\nt2 &#x3D; T(e, 1, T(e, 2, T(e, 3, T(e, 4, T(e, 5, e)))))\nt3 &#x3D; T(e, 1, T(e, 2, T(e, 3, T(e, 4, T(e, 6, e)))))\n\nt1和t2两个二叉树都包含值1，2，3，4，5；t3包含1，2，3，4，6。\n 我们可以编写一个协程来遍历一棵树并返回每个值：\nfunction visit(t)\n    if t ~&#x3D; nil then  -- note: ~&#x3D; is &quot;not equal&quot;\n        visit(t.left)\n        coroutine.yield(t.value)\n        visit(t.right)\n    end\nend\n\n为了比较两棵树，我们可以创建两个访问协程，然后交替读取并比较相邻的值：\nfunction cmp(t1, t2)\n    co1 &#x3D; coroutine.create(visit)\n    co2 &#x3D; coroutine.create(visit)\n    while true\n    do\n        ok1, v1 &#x3D; coroutine.resume(co1, t1)\n        ok2, v2 &#x3D; coroutine.resume(co2, t2)\n        if ok1 ~&#x3D; ok2 or v1 ~&#x3D; v2 then\n            return false\n        end\n        if not ok1 and not ok2 then\n            return true\n        end\n    end\nend\n\nt1和t2参数仅在第一次迭代中用于协程 resume，作为访问参数。后续的resume返回值来自协程 yield，但代码会忽略该值。\n【译者注】第一次迭代调用 visit(t1)，在 visit 函数中先尝试 visit(t1.left)，如果左子树为空，那么就执行coroutine.yield(t.value)，yield 是有返回值的，就是 cmp 函数中 coroutine.resume 传入的 t1，但是这个 t1 参数被忽略了。\n一个更符合Lua语言习惯的版本是使用coroutine.wrap，它返回一个隐藏协程对象的函数：\nfunction cmp(t1, t2)\n    next1 &#x3D; coroutine.wrap(function() visit(t1) end)\n    next2 &#x3D; coroutine.wrap(function() visit(t2) end)\n    while true\n    do\n        v1 &#x3D; next1()\n        v2 &#x3D; next2()\n        if v1 ~&#x3D; v2 then\n            return false\n        end\n        if v1 &#x3D;&#x3D; nil and v2 &#x3D;&#x3D; nil then\n            return true\n        end\n    end\nend\n\n 当协程完成时，next 函数返回nil。\nPython中的生成器（在CLU中为迭代器）Python提供了类似于Lua的协程的生成器，但它们并不是协程，所以值得指出它们之间的差异。主要区别在于，“直白的”程序并不行得通。例如，这里是我们的Lua树和访问者的直接Python翻译：\ndef T(l, v, r):\n    return &#123;&#39;left&#39;: l, &#39;value&#39;: v, &#39;right&#39;: r&#125;\n\ndef visit(t):\n    if t is not None:\n        visit(t[&#39;left&#39;])\n        yield t[&#39;value&#39;]\n        visit(t[&#39;right&#39;])\n\n但是这个直白的翻译行不通：\n&gt;&gt;&gt; e &#x3D; None\n&gt;&gt;&gt; t1 &#x3D; T(T(T(e, 1, e), 2, T(e, 3, e)), 4, T(e, 5, e))\n&gt;&gt;&gt; for x in visit(t1):\n...     print(x)\n...\n4\n&gt;&gt;&gt;\n\n我们失去了1，2，3和5。发生了什么？\n在Python中，那个 visit 函数并没有定义为一个普通函数。因为 body 中包含一个 yield 语句，所以结果是一个生成器：\n&gt;&gt;&gt; type(visit(t1))\n&lt;class &#39;generator&#39;&gt;\n&gt;&gt;&gt;\n\nvisit(t[‘left’]) 的调用并没有运行 visit 函数中的任何代码。它只是创建并返回一个新的生成器，然后被丢弃。为了避 免丢弃这些结果，您必须遍历生成器并重新 yield 它们：\ndef visit(t):\n    if t is not None:\n        for x in visit(t[&#39;left&#39;]):\n            yield x\n        yield t[&#39;value&#39;]\n        for x in visit(t[&#39;right&#39;])\n            yield x\n\n Python 3.3 引入了 yield from 的语法，允许：\ndef visit(t):\n    if t is not None:\n        yield from visit(t[&#39;left&#39;]):\n        yield t[&#39;value&#39;]\n        yield from visit(t[&#39;right&#39;])\n\n生成器对象包含单个 visit 调用的情况下的状态信息，这意味着局部变量值和当前执行的行号。该状态每次生成器重新开始时都会压入调用栈中，然后在每次 yield 时从调用栈中弹出到生成器对象，这只能发生在顶部的调用栈帧。这样，生成器使用与原始程序相同的栈，避免了需要完整的协程实现，但引入了这些令人困惑的限制。\n【译者注】这里我理解是相当于把遍历操作换成了递归操作。\n Python的生成器似乎几乎完全是从CLU复制过来的，CLU创始人提供了这个抽象（以及其他许多东西）。虽然CLU将其称为迭代器，而不是生成器，但CLU树迭代器看起来像这样：\nvisit &#x3D; iter (t: cvt) yields (int):\n    tagcase t\n        tag empty: ;\n        tag non_empty(t: node):\n            for x: int\n                in tree$visit(t.left) do\n                    yield(x);\n                    end;\n            yield(t.value);\n            for x: int\n                in tree$visit(t.right) do\n                    yield(x);\n                    end;\n        end;\n    end visit;\n\n特别是对于检查树的标记联合表示使用的标签，语法有所不同，但是基本结构，包括嵌套的 for 循环，与最初的 Python 版本完全相同。此外，由于CLU是静态类型，因此visit显然被标记为迭代器（iter）而不是函数（proc在CLU中）。由于类型信息的帮助，编译器可以（我假设也）诊断出将visit作为普通函数调用的错误，就像我们那个有 bug 的Python示例一样。\n关于CLU的实现，原始实现者写道：“迭代器是协程的一种形式；然而，它们的使用受到足够的限制，因此仅使用程序栈来实 现。”使用迭代器因此的开销比使用过程要稍微高一些。这听起来与我为Python生成器所提供的解释完全相同。此外，更多信息， 可以参考Abstraction Mechanisms in CLU，特别是第4.2节，第4.3节和第6节。\n协程，线程和生成器首先，协程，线程和生成器看起来都很相似。它们都提供某种形式的并发，但它们在一些重要方面有所不同。\n\n协程通过无并行性提供并发：当一个协程运行时，恢复或让给它的那个协程或线程都没有并行执行。\n 因为协程一个接一个地运行，只在程序的特定点进行切换，所以协程之间可以共享数据而不发生竞争。显式的切换（如第一 个Lua示例中的coroutine.resume或第二个Lua示例中的调用下一个函数）作为同步点，创建 happens-before 边。\n因为调度是显式的（没有任何抢占），并且完全由操作系统之外完成，协程切换最多只需要大约十纳秒，通常甚至更少。启动和退出比线程便宜得多。\n\n\n线程比协程具有更多的能力，但成本更高。额外的能力是并行性，成本是调度器的开销，包括更昂贵的上下文切换和需要在 某种程度上实现预夺。通常操作系统提供线程，线程切换需要几微秒。\n对于这个分类法，Go的goroutines是便宜的线程：goroutine切换接近于几百纳秒，因为Go运行时承担了部分调度工作，但goroutines仍然提供了线程的全部并行性和预夺。 （Java的新轻量级线程基本上与goroutines相同。）\n\n\n生成器提供的能力比协程少，因为只有协程的顶层帧允许 yield。这个帧在对象和调用堆栈之间来回移动，以暂停和恢复它 。\n\n 协程对于编写希望使用程序结构而不是并行的程序是一个有用的构建块。有关详细示例，请参阅我之前的帖子，“Storing Data in Control Flow”。其他示例，请参阅Ana Lúcia De Moura和Roberto Ierusalimschy于2009年发表的论文 “Revisiting Coroutines”。 对于原始示例，请参阅Melvin Conway于1963年发表的论文“Design of a Separable Transition-Diagram Compiler”。\n为什么要在 Go 中实现协程协程是一种并发模式，而不是现有的Go并发库直接提供的。goroutine通常是足够接近的，但我们看到了，它们并不相同，有时候这种差异很重要。\n例如，Rob Pike的2011年的演讲“Lexical Scanning in Go”介绍了text/template包的原始词法器和解析器。它们分别运行在不同的goroutine中，通过一个channel进行通信， imperfectly模拟了一对协程：词法器进程正向前看，而解析器处理最近的。生成器是不够好的——词法器产生许多不同的函数的结果——但full goroutines被证明是有点太多的。goroutines提供的并行性引起了竞争，最终导致放弃该 设计，转而使用词法器将状态存储在对象中，这更像是协程的真实模拟。适当的协程可以避免竞争，并且比goroutines更高效。\n一个预期的未来 coroutines 使用案例在 Go 中的是遍历通用集合。我们讨论了为 Go 添加支持范围 over 函数，这将鼓励集合和其他抽象提供类似 CLU 样式的迭代器函数。迭代器如今可以使用函数值实现，而无需任何语言更改。例如，一个稍微简化 版的树迭代器可以在 Go 中如下所示：\nfunc (t *Tree[V]) All(yield func(v V)) &#123;\n    if t !&#x3D; nil &#123;\n        t.left.All(yield)\n        yield(t.value)\n        t.right.All(yield)\n    &#125;\n&#125;\n\n那个迭代器现在可以如下所示进行调用：\nt.All(func(v V) &#123;\n    fmt.Println(v)\n&#125;)\n\n 也许在 Go 的一个未来版本中，可以以如下方式调用：\nfor v :&#x3D; range t.All &#123;\n    fmt.Println(v)\n&#125;\n\n有时，我们可能需要以一种不适合单层 for 循环的方式遍历集合。二叉树比较就是一个例子：两个迭代需要以某种方式交替进行。正如我们已经看到的，协程可以提供解决方案，让我们将像 Tree.All這樣的“推”迭代器变成返回一个值流，每个调用返回一个值 的“拉”迭代器。\n","slug":"go_coroutines","date":"2024-06-13T04:00:00.000Z","categories_index":"编程","tags_index":"golang,翻译","author_index":"年鲤"},{"id":"5e6bac11d8337953e8e2ec023a083948","title":"NAS 折腾记","content":"因为本人没多少money，加上喜欢折腾，所以并未采用现成的 NAS 方案，选择自己凑配硬件搭建。在21年初初步搭建完成，现在已经平稳运行半年左右，还算满意。现在得空分享一下搭建经验，供同好参考。\n方案介绍不同于常见的多盘位 NAS 机箱，我采用了迷你主机加硬盘盒的形式，通过网线连接路由器提供 NAS 服务。\n其实市面上也有类似的方案，如雷克沙时光机。与多盘位机箱相比，这种方案的优点是占用空间小，可以轻松的的放进包里，硬盘也不会被限制在机器上。\n有优点当然也有缺点，这种方案只适合轻量 NAS 。上面提到的雷克沙时光机仅有一个 USB 接口，在不考虑拓展坞的情况下只能连接一个硬盘。不过我并没有多么变态的容量需求，所以这一点没什么影响。\n硬件\nNUC 5 PPYH  x 1，加上 4G DDR3 内存和 240G 固态硬盘共600元。\n\nNUC 是英特尔推出的迷你主机准系统，因为是准系统，所以需要自购内存硬盘才能跑起来。CPU 为 奔腾 4 核处理器，1.6~2.4GHZ， TDP 只有6w，适合长期运行。\n接口方面，有4个USB3.0，一个HDMI和DP，一个千兆网口，还有3.5mm音频接口。\n这个机子本来是作为普通电脑使用的，顺便作为NAS设备使用完全够用。\n\n西数紫盘 2T x 1，加上硬盘盒共430元。\n\n硬盘没啥好说的，避开叠瓦盘盘然后选个容量适合就OK。硬盘盒就看支不支持USB3.0和自动休眠，材质的话金属散热好点。\n软件系统Windows 是不可能用 Windows 的，一开始我看同事在用 openSUSE ，所以也装了个尝尝鲜。总体使用体验还是可以的，YaST 工具非常好用。只可惜社区基本凉凉，搜到的文章资料又少又老。\n后来换了Manjaro，基于大名鼎鼎的 Arch Linux，使用体验非常好，软件包又全又新。比如 docker、hugo（静态网站生成器） 可以直接用 pacman 命令安装，go 版本基本与官网保持同步。中间出过重启会卡住的问题，将内核版本降到5.4就OK了。\n应用\ndocker，运行各种应用\nportainer，docker 管理\nsamba，网络共享挂载的磁盘\nnetdata，监控机器运行状态\naria2+AriaNg、qbittorroent-nox，文件下载\ncloudreve、filebrowser、syncthing，云盘，文件同步\nemby，音视频播放\nhugo、hexo，个人博客\nnginx，部署简单的导航页\n各种小玩意，minikube等\n\n配置基本就是网络配置（固定ip，防火墙），各种软件的安装配置，以及编写 systemd service 开机启动，fstab挂载磁盘。fstab挂载磁盘要小心，建议先试一下，直接重启并且无法挂载磁盘会导致系统进不去，这时就需要进救援模式修复了（亲身经历）。\n详细的以后有空再开篇分享吧，这里先挖个坑。\n总结事实上，这个方案确实算不上正经的 NAS，尤其还缺少云同步的功能。但是好在什么都能干，在局域网内跨设备共享文件，也基本满足了我的要求。速度在110MB/s左右，瓶颈在于网络带宽，如果更换为万兆网卡应该可以提升一点速度，但是不多，接口和磁盘（SATA、USB3.0、机械硬盘）会成为新的瓶颈。\n","slug":"nas1","date":"2021-07-26T03:29:41.000Z","categories_index":"折腾","tags_index":"硬件,nas","author_index":"年鲤"},{"id":"4dbb2ad4d40b43ce8f2a583cb86bc39c","title":"Golang标准库：sync","content":"sync 包​    虽然go主要通过协程和通道来完成同步，但是在某些情况下使用sync包提供的同步更加简洁和巧妙。下面列举sync包的应用场景及相应的用法和坑。\n一：单例单例是经常要用到的一个编程模式，go最简单的单例实现就是使用 sync.One\n示例package main\n\nimport (\n\t&quot;fmt&quot;\n\t&quot;math&#x2F;rand&quot;\n\t&quot;sync&quot;\n\t&quot;time&quot;\n)\n\ntype Instance struct &#123;\n\tID int\n&#125;\n\nvar (\n\tonce     sync.Once\n\tinstance Instance\n)\n\nfunc GetInstance() Instance &#123;\n\tisNew :&#x3D; false\n\tonce.Do(func() &#123;\n\t\trand.Seed(time.Now().UnixNano())\n\t\tinstance &#x3D; Instance&#123;\n\t\t\tID: rand.Intn(100),\n\t\t&#125;\n\t\tisNew &#x3D; true\n\t&#125;)\n\tif isNew &#123;\n\t\tfmt.Printf(&quot;return new instance \\n&quot;)\n\t&#125; else &#123;\n\t\tfmt.Printf(&quot;return instance that already exist. \\n&quot;)\n\t&#125;\n\treturn instance\n&#125;\n\nfunc main() &#123;\n\tfor i :&#x3D; 1; i &lt;&#x3D; 3; i++ &#123;\n\t\tfmt.Printf(&quot;got instance: %d \\n&quot;, GetInstance().ID)\n\t&#125;\n&#125;\n\n\n输出\nreturn new instance \ngot instance: 13 \nreturn instance that already exist. \ngot instance: 13 \nreturn instance that already exist. \ngot instance: 13\n\n\n\n说明从结果可以看到虽然调用了多次 GetInstance函数，得到的却始终是同一个示例。这是因为once.Do只会执行一次。\n注意点不要在套娃使用同一个Once，会造成死锁，如：\nfunc ErrOnce() &#123;\n\tvar o sync.Once\n\to.Do(func() &#123;\n\t\to.Do(func() &#123;\n\t\t\tfmt.Println(&quot;never print&quot;)\n\t\t&#125;)\n\t&#125;)\n&#125;\n\nOnce内有一个互斥锁，这样使用会内层无法加锁\n二：并发安全sync提供的互斥锁可以保证数据（比如一个map）的并发安全\n示例type RWMap struct &#123;\n    sync.RWMutex\n    m map[int]int\n&#125;\n\nfunc (m *RWMap) Set(k int, v int) &#123;\n    m.Lock()\n    defer m.Unlock()\n    m.m[k] &#x3D; v\n&#125;\n\n&#x2F;&#x2F;...\n\n\n说明在对数据进行读写操作前加锁，操作后解锁即可。\n对于map而言，这样实现并发安全性能不高，可以使用sync.Map。\n三：一等多如果有一个协程需要等待多个协程结束的场景，可以考虑sync.WaitGroup\n示例package main\n\nimport (\n\t&quot;fmt&quot;\n\t&quot;math&#x2F;rand&quot;\n\t&quot;sync&quot;\n\t&quot;time&quot;\n)\n\nvar wg sync.WaitGroup\n\nfunc Work(no int) &#123;\n\trand.Seed(time.Now().UnixNano())\n\tfmt.Printf(&quot;work - %d start.\\n&quot;, no)\n\ttime.Sleep(time.Duration(rand.Intn(5)) * time.Second)\n\tfmt.Printf(&quot;work - %d done\\n&quot;, no)\n    wg.Done() &#x2F;&#x2F; 减少一个等待个数，等同于Add(-1)\n&#125;\n\nfunc main() &#123;\n\tfor i :&#x3D; 0; i &lt; 3; i++ &#123;\n\t\twg.Add(1) &#x2F;&#x2F; 增加一个等待个数\n\t\tgo Work(i)\n\t&#125;\n\twg.Wait() &#x2F;&#x2F; 阻塞至等待个数归零，不能小于0\n&#125;\n\n结果\nwork - 2 start.\nwork - 0 start.\nwork - 0 done.\nwork - 1 start.\nwork - 1 done.\nwork - 2 done.\n\n说明见注释\n注意点不要复制WaitGroup的值，而应使用指针，因为要保证所有操作在同一个WaitGroup上。\n四：多等一如果有多个协程需要等待一个协程的场景，可以考虑sync.Cond\npackage main\n\nimport (\n\t&quot;fmt&quot;\n\t&quot;sync&quot;\n\t&quot;time&quot;\n)\n\nvar (\n\tdone &#x3D; false &#x2F;&#x2F; 等待条件，由被等待的协程控制\n\tc    &#x3D; sync.NewCond(&amp;sync.Mutex&#123;&#125;)\n)\n\nfunc consume(i int) &#123;\n\tc.L.Lock() &#x2F;&#x2F; 读条件前加锁\n\tfor !done &#123;\n\t\tfmt.Printf(&quot;c - %d waiting\\n&quot;, i)\n\t\tc.Wait() &#x2F;&#x2F; 先解锁，后挂起等待被唤醒，唤醒后再加锁\n\t&#125;\n\tfmt.Printf(&quot;c - %d exit\\n&quot;, i)\n\tc.L.Unlock() &#x2F;&#x2F; 读条件后解锁\n&#125;\n\nfunc main() &#123;\n\tfor i :&#x3D; 0; i &lt; 3; i++ &#123;\n\t\tgo consume(i)\n\t&#125;\n\tfmt.Println(&quot;do something&quot;)\n\ttime.Sleep(3 * time.Second)\n\tfmt.Println(&quot;done&quot;)\n\tc.L.Lock() &#x2F;&#x2F; 写条件前加锁\n\tdone &#x3D; true\n\tc.L.Unlock()  &#x2F;&#x2F; 写条件后解锁\n\tc.Broadcast() &#x2F;&#x2F; 广播通知所有协程，协程将会抢锁读条件\n\ttime.Sleep(time.Second) &#x2F;&#x2F; 等待协程结束\n&#125;\n\n结果\nc - 0 waiting\nc - 2 waiting\nc - 1 waiting\ndo something\ndone\nc - 1 exit\nc - 2 exit\nc - 0 exit\n\n\n说明见注释，除了广播通知还可以用Signal()单个通知。\n此外通过关闭通道实现一对多通知也是非常不错的方法。\n注意点\n调用Wait前后要加解锁，如果不加锁Wait内部无法解锁，如果不解锁其他协程无法加锁\n同样不可复制值\n遵循FIFO规则，即先到先出\n\n","slug":"go-sync","date":"2021-07-04T05:35:41.000Z","categories_index":"编程","tags_index":"golang,标准库","author_index":"年鲤"},{"id":"41d158fdf8b143deea2f819f3d3b843b","title":"Golang内存泄露","content":"防患未然\n避免引用大字符串和大切片的一小部分导致无用部分无法被回收，可以复制有用部分到新串和新切片以解除引用。对于切片，也可以将无用部分设nil。\n避免因为代码设计中的一些错误而导致一些协程处于永久阻塞状态。如：\n从一个永远不会有其它协程向其发送数据的通道接收数据；\n向一个永远不会有其它协程从中读取数据的通道发送数据；\n被自己死锁了；\n和其它协程相互死锁了；\n等等。\n\n\n对于不再使用使用的time.Ticker要记得调用Stop方法。\n避免将终结器设置到一个循环引用值组中的一个值上。\n避免无脑积压defer，可以包裹在一个匿名函数内，提前释放不再使用的资源。\n\n亡羊补牢使用 go pprof 分析定位内存泄露的地方\n","slug":"go-leak","date":"2021-06-30T03:38:41.000Z","categories_index":"编程","tags_index":"golang,最佳实践","author_index":"年鲤"},{"id":"7d914a4575876c2b19b68d691e332d41","title":"Golang最佳实践：Functional Option","content":"使用场景在初始化结构体时常常会碰到这样的情况，一些字段是不能为空且没有默认值，一些字段是不能为空但有默认值，还有的的则可以为空。\n举例来说，有这么一个结构体\ntype Pool struct &#123;\n\tCapacity       int32\n\tExpiryDuration time.Duration\n\tLogger         Logger\n&#125;\n\n\nCapacity表示池容量，不能为空且没有默认值（可以有，这里只是假设）\n\nExpiryDuration表示过期时间间隔，不能为空但有默认值\n\nLogger表示日志，可以为空\n\n\n在这种情况下，由于需要使用默认值，所以直接用字面量初始化是不合适的。一般做法是提供初始化函数，比如如下：\nfunc NewDefaultPool(cap int32) (*Pool,error) &#123;...&#125;\n\nfunc NewPoolWithLogger(cap int32, logger Logger) (*Pool, error) &#123;...&#125;\n\n缺点比较繁琐，并且因为go不支持重载，所以还得使用不同的函数名。\n解决方案一：Config做法把可选配置（有默认值或可以为空）的字段提到单独的结构体里\ntype Config struct &#123;\n\tExpiryDuration time.Duration\n\tLogger         Logger\n&#125;\n\n然后提供一个初始化函数\nfunc NewPool(cap int32, conf *Config) (*Pool, error) &#123;...&#125;\n\n缺点这是比较常见的做法，但是需要额外的结构体，并且要判断Config是否为nil\n解决方案二：Builder做法把结构体包装为一个Builder\ntype PoolBuilder struct &#123;\n    Pool *Pool\n    Err  error\n&#125;\n\nfunc (pb *PoolBuilder) Create(cap int32) *PoolBUilder &#123;...&#125;\n\nfunc (pb *PoolBuilder) WithLogger(logger Logger) *PoolBUilder &#123;...&#125;\n\nfunc (pb *PoolBuilder) Build() (*Pool, error)\n\n然后通过链式调用构造结构体\npb :&#x3D; &amp;PoolBuilder&#123;&#125;\np, err :&#x3D; pb.Create(100).WithLogger(logger).Build()\n\n缺点这样还是需要额外的结构体，如果直接为Pool实现方法，无法很好进行错误处理\n最佳实践：Functional Options做法首先声明一个函数类型\ntype Option func(*Pool)\n\n然后声明一组函数\nfunc WithExpiryDuration(t time.Duration) Option &#123;\n    return func(p *Pool) &#123;\n        p.ExpiryDuration &#x3D; t\n    &#125;\n&#125;\n\nfunc WithLogger(logger Logger) Option &#123;\n    return func(p *Pool) &#123;\n        p.Logger &#x3D; logger\n    &#125;\n&#125;\n\nfunc NewPool(cap int32, options ...func(*Pool)) (*Pool, error) &#123;\n    p :&#x3D; &amp;Pool&#123;\n        Capacity: \t\tcap\n        ExpiryDuration: time.Hour &#x2F;&#x2F;默认值\n    &#125;\n    \n    for _, option :&#x3D; range options &#123;\n        option(p)\n    &#125;\n    \n    &#x2F;&#x2F;...\n    \n    return p, nil\n&#125;\n\n最后构造方式如下\np, err :&#x3D; NewPool(100, WithLogger(Logger))\n\n优点\n直觉式的编程\n高度的可配置化\n很容易维护和扩展\n自文档\n对于新来的人很容易上手\n没有什么令人困惑的事（是nil 还是空）\n\nOK，吹完了，收工\n","slug":"go-option","date":"2021-06-29T03:38:41.000Z","categories_index":"编程","tags_index":"golang,最佳实践","author_index":"年鲤"},{"id":"a2989562c244afbcf550859cf239a080","title":"Golang：交叉编译","content":"\n\n什么是交叉编译交叉编译是指在一个平台上生成另一个平台上的可执行程序。\n比如要在Windows系统上生成可以在Linux上运行的程序时，就需要用到交叉编译。\nGolang交叉编译编译参数不同的编译参数决定了最后生成的程序能在什么平台上运行，默认为当前编译平台。\nGOOS 目标平台的系统，常用值：windows、darwin（macOS）、linux\nGOARCH 目标平台CPU架构， 常用的值 ：amd64、386、arm64、arm\nGOARM  只有 GOARCH 是 arm64 才有效, 表示 arm 的版本, 目前只能是 5, 6, 7 其中之一\nCGO_ENABLED 值为1或0，分别表示开启或关闭CGO，默认开启（值为1）。CGO用于Go调用C代码\nCC 当支持交叉汇编时(即 CGO_ENABLED=1), 编译目标文件使用的 c 编译器\nCXX 当支持交叉汇编时(即 CGO_ENABLED=1), 编译目标文件使用的 c++ 编译器\nAR 当支持交叉汇编时(即 CGO_ENABLED=1), 编译目标文件使用的创建库文件命令\nGo支持的平台GOOS 和 GOARCH的不同组合就代表不同平台，可以使用go tool dist list命令查看支持的平台\ngo 1.16.3 版本支持的平台如下：\n\nlinux\n\n386，amd64，arm，arm64，mips，mips64，mips64le，mipsle，riscv64，ppc64，ppc64le，s390x\n\n\nwindows\n\n386，amd64，arm\n\n\ndarwin，ios\n\namd64，arm64\n\n\nandroid\n\n386，amd64，arm，arm64\n\n\nfreebsd，netbsd\n\n386，amd64，arm，arm64\n\n\nopenbsd\n\n386，amd64，arm，arm64，mips64\n\n\ndragonfly，illumos，solaris\n\namd64\n\n\nplan9\n\n386，amd64，arm\n\n\njs\n\nwasm\n\n\naix\n\nppc64\n\n\n\n其中386表示x86 32位，amd64表示x86 64位。\n具体操作下面列举几种常见的交叉编译场景的具体命令操作\nMac 下编译 Linux 和 Windows 64位可执行程序\nCGO_ENABLED&#x3D;0 GOOS&#x3D;linux GOARCH&#x3D;amd64 go build main.go\nCGO_ENABLED&#x3D;0 GOOS&#x3D;windows GOARCH&#x3D;amd64 go build main.go\n\nLinux 下编译 Mac 和 Windows 64位可执行程序\nCGO_ENABLED&#x3D;0 GOOS&#x3D;darwin GOARCH&#x3D;amd64 go build main.go\nCGO_ENABLED&#x3D;0 GOOS&#x3D;windows GOARCH&#x3D;amd64 go build main.go\n\nWindows 下编译 Mac 和 Linux 64位可执行程序\nSET CGO_ENABLED&#x3D;0\nSET GOOS&#x3D;darwin\nSET GOARCH&#x3D;amd64\ngo build main.go\n\nSET CGO_ENABLED&#x3D;0\nSET GOOS&#x3D;linux\nSET GOARCH&#x3D;amd64\ngo build main.go\n\n可以通过将参数写入环境变量，这样就不用每次都要设置参数\n难点：CGO上文操作示例都关闭了CGO，但当go项目包含C代码的调用就需要开启CGO，然而这会带来问题。\n例如在一个嵌入式开发场景中，需要使用github.com/mattn/go-sqlite3驱动sqlite，并且目标平台是arm架构，此时go本身的工具链不足以完成编译。\n解决方法就是下载对应的编译工具链\narm编译工具链官网地址\n以Windows为例，下载gcc-arm-none-eabi-XXXX-major-win32.zip\n下载完成后解压并将其下bin文件夹加入环境变量，最后将编译参数CC的值设为arm-none-eabi-gcc\n这里简单提一下交叉编译工具链的命名规则：\narch [-vendor] [-os] [-(gnu)eabi]\n\narch - 体系架构，如ARM，MIPS\nvendor - 工具链提供商\nos - 目标操作系统\neabi - 嵌入式应用二进制接口（Embedded Application Binary Interface）\n\n","slug":"go1","date":"2021-05-06T03:38:41.000Z","categories_index":"速查,项目部署","tags_index":"golang,编译","author_index":"年鲤"},{"id":"3b8d2c61522914168806280ffb0906e3","title":"MySQL：MVCC","content":"\n\n实现原理innoDB的行记录格式中有6字节事务ID的和7字节的回滚指针，通过为每一行记录添加这两个额外的隐藏值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。\n但是InnoDB并不存储这些事件发生时的实际时间，相反它只存储这些事件发生时的系统版本号。这是一个随着事务的创建而不断增长的数字。每个事务在事务开始时会记录它自己的系统版本号。每个查询必须去检查每行数据的版本号与事务的版本号是否相同。\n当隔离级别是REPEATABLE READ时这种策略是如何应用到特定的操作的。\nSELECT\n当隔离级别是REPEATABLE READ时select操作，InnoDB必须每行数据来保证它符合两个条件：\n\nInnoDB必须找到一个行的版本，它至少要和事务的版本一样老(也即它的版本号不大于事务的版本号)。这保证了不管是事务开始之前，或者事务创建时，或者修改了这行数据的时候，这行数据是存在的。\n这行数据的删除版本必须是未定义的或者比事务版本要大。这可以保证在事务开始之前这行数据没有被删除。符合这两个条件的行可能会被当作查询结果而返回。\n\nINSERT\nInnoDB为这个新行记录当前的系统版本号。\nDELETE\nInnoDB将当前的系统版本号设置为这一行的删除ID。\nUPDATE\nInnoDB会写一个这行数据的新拷贝，这个拷贝的版本为当前的系统版本号。它同时也会将这个版本号写到旧行的删除版本里。\n当记录不满足SELECT的第一个条件时，就读取它的历史版本，而具有回滚作用的undo log就在这里用上了。\n优缺点这种额外的记录所带来的结果就是对于大多数查询来说根本就不需要获得一个锁。他们只是简单地以最快的速度来读取数据，确保只选择符合条件的行。这个方案的缺点在于存储引擎必须为每一行存储更多的数据，做更多的检查工作，处理更多的善后操作。\n兼容性MVCC只工作在REPEATABLE READ和READ COMMITED隔离级别下。READ UNCOMMITED不是MVCC兼容的，因为查询不能找到适合他们事务版本的行版本；它们每次都只能读到最新的版本。SERIABLABLE也不与MVCC兼容，因为读操作会锁定他们返回的每一行数据。\n","slug":"mysql2","date":"2021-05-05T05:30:02.000Z","categories_index":"学习笔记,mysql","tags_index":"mysql实现原理","author_index":"年鲤"},{"id":"30e17c6fd6cc1b89b9fcc4be10f9ed75","title":"MySQL：redo 和 undo","content":"\n\nredo log 作用redo log 用以保证事务的持久性，当数据库突然宕机后重启就需要使用 redo log 恢复已经提交但是没来得及同步到磁盘上的事务。\n再深挖一下为什么数据库宕机重启就需要恢复数据呢，这是因为直接将修改的数据页同步到磁盘意味着频繁的随机写入操作。懂点磁盘运行原理的同学都应该知道这样效率多低，但一直放在内存而不实时刷盘又容易丢失数据。 redo log 就可以解决这个问题，虽然也需要同步到磁盘，但是由于采取顺序写入的方式，所以同时具有效率高和不易失的优点。\n这样一来，数据库就可以从容地将修改的数据页写入磁盘而不用怕突然宕机，因为可以根据 redo log 进行恢复。\n工作机制在InnoDB中通过Force Log at Commit机制实现事务的持久性，即当事务提交时，必须将重做日志缓冲写入重做日志文件后才算提交成功。这样就能保证成功提交的事务都被记录了下来，但是也不是绝对，后面再讲。\n两阶段提交\n这个与MySQL的binlog有关，binlog是MySQL Server层实现的，主要用于数据备份恢复和主从复制。为了保证两份日志的逻辑一致性MySQL采用了两阶段提交，提交过程可简略表示为：\n写redo log （第一阶段：prepare）-&gt;  写binlog -&gt; 写redo log (第二阶段：commit)\n恢复策略可简略表示为：\n\n如果redo log显示处于commit状态，说明redo log和binlog均已记录了事务，则直接提交事务\n\n如果redo log显示处于prepare状态，还要看binlog是否记录了完整的事务，如果是那么就提交，否则就回滚事务\n\n\n这样可以保证直接通过redo log恢复的数据库和通过binlog恢复或者说同步的（从）数据库一致\n组提交\n虽然redo log是顺序写入比随机写入快不少，但总归还是会被内存缓冲的写入速度降维打击。组提交就是用来解决这个瓶颈的，简单来说就将多个事务的写入的重做日志缓冲一次性同步到硬盘。\n但是开启binlog后，binlog也有这个瓶颈，并且由于要保持两份日志的一性使得redo log组提交也废了（需要加锁以同步提交顺序和写入顺序，从而导致其他事务无法提交）。于是乎binlog也搞了个组提交，称为BLGC，就是binlog组提交的首字母缩写。\nBLGC分为三个阶段：\n\nflush阶段，将binlog写入内存\nsync，一次性将多个事务的binlog刷新到磁盘（与redo log组提交同理，提高了效率）\ncommit阶段，按顺序完成事务的提交\n\n最精华的就是最后按顺序完成事务的提交，MySQL将要提交的事务按顺序放入一个队列，队列中的第一个事务称为leader，其他事务称为follower，在最后阶段leader按顺序调用InnoDB事务的提交。\n特点如果数据页已经同步到了磁盘（通过LSN判断），真正持久化了，那么对应的 redo log 也就没用了。所以 redo log 有用的往往只有最新的一小段，于是可以采用循环写的方式，整体所占空间是固定的。\nredo log的存储都是以 块(block) 为单位进行存储的，每个块的大小为512字节。同磁盘扇区大小一致，可以保证块的写入是原子操作。\n参数调优innodb_flush_log_at_trx_commit这个参数决定了将redo log缓存刷入磁盘的时机，默认为1，代表提交时立即刷入，0代表交给master thread完成，而master thread每一秒刷入1次，2代表写入文件系统缓存，刷入交给操作系统完成。可以将参数修改为0或2提高数据库性能，但是会失去事物的ACID特性。\nundo log 的作用undo log的作用有两个：1. 回滚事务。2. 实现MVCC（这个有空另写一篇）\n工作机制undo log是逻辑日志，所以进行的是逻辑上的反向操作，插入一条数据就删除一条数据，更新一条数据就反向更新一条数据。由于同时其他事务，并不能保证数据和原来一模一样，因此不能理解成让数据库回到某一状态。\n特点由于undo log也需要持久化，所以undo log会产生redo log\n事务提交后不能马上删除undo log，因为在MVCC还可能用的到。最后删除时记录还会寻找同一数据页中寻找其他可以删除的记录，这是为了避免随机读写。\n参数调优innodb_purge_batch_size可以设置每次purge要清理的undo page数量。参数越大则回收的页越多，磁盘空间和分配开销越小，CPU和磁盘IO开销越大。\n","slug":"mysql1","date":"2021-04-27T04:55:29.000Z","categories_index":"学习笔记,MySQL","tags_index":"mysql,事务,调优","author_index":"年鲤"},{"id":"dcd5fd0682cc948a30be92bebe89ab9a","title":"TCP：序列号与滑动窗口","content":"\n\n序列号的作用上一篇博客中提到了序列号在建立tcp连接中的作用。不光如此，序列号还是tcp可靠传输的基础。\n为了可靠传输就要防止丢包，所以接受端需要向发送端确认，就像我们收到快递包裹也要确认收货。类比来讲，序列号就像是快递单号。\n但是与现实不同的是，tcp包数量庞大。这就造成：\n\n单个单个确认会浪费网络资源\n发送端在等待确认时无事可做会浪费时间和硬件资源\n\n所以最好批量发送和确认，发送端一次性发送一组tcp包，接受端一次性确认一组tcp包。\n怎么一次性确认多个包很简单，序列号设计为连续的，确认顺序最靠后的包就代表收到了之前所有的包。考虑到可能出现丢包，如果收到如下一组包（数字代表包的序列号）：\n{… …，233，234，235，237，238}\n此时为了保证收到缺失的包应确认235，而237，238都会当做没收到，这样发送端就会再次发送235之后的包。为了保证可靠性，这么做是值得的。\n实际中确认报文（ACK）发送的序列号要加1，表示从这个序列号的包开始发送。\n滑动窗口的作用在批量发包时，一次性发多少数量是个问题，滑动窗口就代表这个数量。由于主要需要考虑接受端的能力，所以由接收端发送给发送端（两端间会往来数据，这里指广义上的数据接受端和发送端）。\n发送端收到窗口大小后，就会计算发了多少包，剩余多少容量以保证保证不超过窗口大小，直到窗口更新。\n发送的时机将窗口更新和ACK报文合并发送可以提高网络效率。\n","slug":"network2","date":"2021-04-20T05:40:26.000Z","categories_index":"学习笔记,网络","tags_index":"tcp","author_index":"年鲤"},{"id":"b7863f675c1f74636fbdcd034261f5ad","title":"TCP：握手挥手","content":"\n\n什么是三次握手和四次挥手三次握手和四次挥手是http建立连接和关闭连接过程的形象描述。这个说法比较有名，因为我们通常喜欢以类比的方式来认识未知的事物。\n但是从本质原因出发去认识事物或许可以获得更深刻的认识。\n为什么要三次握手主要是因为要防止旧的重复连接初始化造成混乱\n在网络状况较差的情况下，客户端在和服务端建立连接前可能会多次发起连接，为了防止因此引起混乱就需要有能够及时中止错误连接的机制。\n首先要明白的一点是服务端无法知道当前收到的连接请求报文是否是最新的，所以服务端要向客户端确认是否为历史连接。\n那么客户端怎么判断是否为历史连接呢？简单来说就是客户端随机发给服务端一个数，服务端把这个数加一发还给客户端，客户端判断发送的数和收到的数和收到的数是否满足加一关系就可以判断是否为历史连接。\n相对具体点的流程如下：\n\n客户端发送SYN报文，其中包含客户端初始序列号seq_c\n服务端收到SYN报文，发送ACK确认报文，其中包含序列号seq_c+1\n服务端发送SYN报文，其中包含服务端初始序列号seq_s\n客户端收到ACK确认报文和SYN报文\n如果收到seq_c+1，发送ACK确认报文，包含序列号seq_s+1，连接建立\n否则，发送RST报文中止连接\n\n\n\n其中有两点要注意：\n\n因为第二步和第三步都是由服务端发送报文，所以可以并到一起，最终只要三次通信。\n服务端也要发送自己的初始序列号，因为序列号在之后的通信中也要用到。\n\n为什么要四次挥手TCP连接是双向的，所以关闭连接同样需要双向确认。一方发起关闭连接请求报文，一方确认，从而关闭一个方向的连接。这个过程重复两次就有了四次挥手。\n相对具体点的流程如下：\n\nA端发送FIN报文\nB端收到FIN报文，发送ACK确认报文\n等待一端时间后，B端发送FIN报文\nA端收到FIN报文，发送ACK确认报文并等待一段时间\n\n其中两段等待时间需要注意：\n\n第三步中的需要等待时间是因为TCP协议栈不能替上层应用做出关闭连接的决定，所以要等上层应用反应，这也是不能合并为三次通信的原因\n第四步需要等待时间有两个原因\n防止旧连接延迟到达的包影响新连接，空窗期可以直接丢弃这些包\n保证对方连接正确关闭，如果最后的ACK确认报文丢了，还可以处理重发的FIN包\n\n\n\n当然最后的等待时间太长也不好，端口资源是有限的，占着茅坑不拉屎容易出问题。\n","slug":"network1","date":"2021-04-18T05:08:29.000Z","categories_index":"学习笔记,网络","tags_index":"tcp","author_index":"年鲤"},{"id":"56062437aab4c6050adec4f20774c673","title":"杂谈（一）","content":"\n\n\n今天到手的就是上面这把黑峡谷x3了，现在打字用的就是它。\n直肠子的一句话总结300价位 、 87配列、双模（2.4g wifi和有线）、手感不错 （凯华box轴体）、可充电\n配件送了type-c数据线、手托、拔键器、防尘盖，还算良心。目前没发现啥问题。\n之所以买了这把键盘呢，主要还是早有预谋加热血上头。本来一直用的是100价位的入门键盘，自从摸了同事的键盘就想着换把键盘，加上最近桌面被各种线搞得乱七八糟的，半夜趁自己不备买了键盘。其实300价位的机械键盘倒也不是很贵，主要是没钱.jpg\n细节\n上手的第一感觉就是沉，1.5kg的毛重对便携性还是有点影响的。\n无线接收器可以磁吸在背面（有个凹槽），取放比较方便，吸力还可以，带出门时得注意点。\n线材1.5m左右，个人觉得长度合适，我原来那个键盘线就长的离谱。普通USB口加type-C口，可分离（废话），表面是编织网，质量看上去不错。\n据说可能碰到歪轴问题，黑白配色可以一定程度上遮盖这一问题，厂商真是鬼才。\n\n关于手感手感这个东西比较主观，我选的是凯华box流沙金轴，对应常说的茶轴。对比我原来用的青轴，有声音但是不会吵得让人心烦，也没丢了段落感，哒哒哒敲得还是挺开心的。\n关于颜值颜值这个东西比较主观（似曾相识燕归来），我选的是黑白双色的，还有其他花里胡哨的配色。但是个人觉得花里胡哨得不够惊艳，值得一提的是还有一款猛男配色hh。总之颜值这块从我看来不算高。\n性价比性价比的前提是符合核心要求，抛开要求讲性价比其实不太合理。但硬要说的话，那就一个字：高。相信大多数人最在意的还是手感和功能性，这把键盘这两项都还算可以的情况下300的价位也比较亲民。\n","slug":"misc1","date":"2021-04-18T02:17:09.000Z","categories_index":"杂谈,折腾日常","tags_index":"硬件,键盘","author_index":"年鲤"},{"id":"9661b4a0c78c3413d585a5b60f2d0c10","title":"Redis（五）：整数集合","content":"\n\n整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，它可以保存类型为int16_t、int32_t或者int64_t的整数值，并且保证集合中不会出现重复元素。\n整数集合结构示意图\n\n\nencoding属性的值表示底层数组的整数类型。\nlength属性的值表示数组的长度。\ncontents就是底层整数数组。\n\nredis支持将不同类型的整数添加到整数数组中，但是不同类型的整数所占空间不同，这意味着需要额外的操作。\n当新元素的类型比整数集合现有所有元素的类型都要长时，需要升级操作。\n升级操作\n根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间。\n\n将底层数组现有的所有元素都转换成与新元素相同的类型，并将类型转换后的元素放置到正确的位上，而且在放置元素的过程中，需要继续维持底层数组的有序性质不变。从末尾开始搬可以避免位置冲突。\n\n将新元素添加到底层数组里面。\n\n\n因为引发升级的新元素的长度总是比整数集合现有所有元素的长度都大，所以这个新元素的值要么就大于所有现有元素而被放在末尾，要么就小于所有现有元素而被放在开头。\n通过升级操作，整数集合在具备灵活性的同时还能节约内存。要注意的是没有相对应的降级操作。\n总结整数集合比较简单，要注意的是超出长度的的整数类型时引起的升级操作。\n","slug":"redis5","date":"2021-03-12T05:47:30.000Z","categories_index":"学习笔记,Redis","tags_index":"Redis数据结构与对象","author_index":"年鲤"},{"id":"b7745da1129b3624e0119421c5f639dd","title":"Redis（四）：跳跃表","content":"\n\n跳跃表支持平均O（logN）、最坏O（N）复杂度的节点查找，还可以通过顺序性操作来批量处理节点。在大部分情况下，跳跃表的效率可以和平衡树相媲美，而且实现还更加简单。\n跳跃表结构解析\n\nheader：指向跳跃表的表头节点。\n\ntail：指向跳跃表的表尾节点。\n\nlevel：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）。\n\nlength：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内）。\n\n\n首先要注意的是跳表是有序的，从结构示意图中可以看到节点按score（即图中的1.0、2.0、3.0）从小到大排列，离表头越远，score越大。\n重点是节点的结构，节点包含的属性可以分为两部分讲，一部分用来跳跃，一部分用来保存对象。\n跳跃可以按方向分为两种：向表尾跳和向表头跳，分别通过层和后退指针完成。\n结构示意图中L1、L2、L3 …代表的就是层，可以看到一个节点的层不止一个，高层跳的远（跨度大），低层跳的近（跨度小）。而后退指针只有一个（图中的BW），所以只能以固定的跨度1向表头跳。\n查找节点以升序表为例，查找节点的流程如下：\n\n找到表头节点顶层\n\n比较当前层下一节点（层指针指向的节点）和目标节点\n\n如果相等，找到节点，流程结束\n如果小于目标节点，那么跳到下一节点的当前层，重复步骤2\n如果大于目标节点或者到了表尾（指向null），那么跳到当前节点的下一层，重复步骤2\n\n\n\n如果无法再重复步骤2还没找到节点，说明节点不存在。要注意的是由于Redis允许重复的score值，所以进行对比操作时，不仅要检查 score 值，还要检查 member域。\n查找节点的复杂度平均**O(logN)，最坏O(N)**。\n插入节点\n找到要插入的位置，为其插入第一层。\n通过指定的概率p和随机算法确定是否插入第N层，N不大于最大层数，默认32。\n\n如果概率p为0.5，那么可以用抛硬币来类比这个过程，如果是正面插入一层，然后再抛，否则退出。\n可以推导出如果p越大，那么高层节点越多，查找节点越快，占用空间越多。\n插入新节点复杂度平均 O(logN)，最坏O(N) 。\n删除节点相比之下，删除节点操作较为简单，和单链表删除节点所做操作大体相同。删除节点的复杂度也是平均 **O(logN)，最坏O(N)。删除分为内节点复杂度为O(N)**，N为删除节点数量。\n总结redis跳跃表以一种较为简单的方式实现和平衡树相同的效率，基本原理是建立一些“捷径”，免于逐节点比对。但是由于捷径是随机产生的，稳定性上还是不如平衡树。\n","slug":"redis4","date":"2021-03-11T05:26:55.000Z","categories_index":"学习笔记,Redis","tags_index":"Redis数据结构与对象","author_index":"年鲤"},{"id":"f9b13b980458a49d4d916f8fb1d54566","title":"Redis（三）：字典","content":"\n\n字典在Redis中的应用相当广泛，比如Redis的数据库就是使用字典来作为底层实现的，对数据库的增、删、查、改操作也是构建在对字典的操作之上的。\n字典结构解析Redis的字典使用哈希表作为底层实现，结构如图：\n\ntable属性是一个数组，数组中的每个元素都是一个指向dict.h/dictEntry结构的指针，每个dictEntry结构保存着一个键值对。size属性记录了哈希表的大小，也即是table数组的大小，而used属性则记录了哈希表目前已有节点（键值对）的数量。sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面。\nindex = hash &amp; sizemask;\n其中hash是对key进行哈希运算得出的。\n解决键冲突当出现两个键值对计算出的索引值index相同即发生键冲突时，Redis通过链地址法来解决冲突，索引值相同的键值对通过next指针以单向链表的形式连接在一起。\n要注意的一点是由于没有表尾指针，出于速度考虑，新节点直接插入表头，所以插入节点的复杂度为**O(1)**。\nrehash（重新散列）随着操作的不断执行，哈希表保存的键值对会逐渐地增多或者减少，为了让哈希表的负载因子（load factor）维持在一个合理的范围之内，当哈希表保存的键值对数量太多或者太少时，程序需要对哈希表的大小进行相应的扩展或者收缩。扩展和收缩哈希表的工作可以通过执行rehash（重新散列）操作来完成。\n这个过程类似于搬家，所以会有旧房子ht[0]和新房子ht[1]，首先要判断是否需要搬家，通过公式计算负载因子：\nload_factor = ht[0].used / ht[0].size\n满足以下条件时执行扩展操作1）服务器目前没有在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子大于等于1。\n2）服务器目前正在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子大于等于5。\n满足负载因子小于0.1时执行收缩操作。\nrehash具体操作步骤：\n为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量（也即是ht[0].used属性的值）：\n\n如果执行的是扩展操作，那么ht[1]的大小为第一个大于等于ht[0].used*2的2的n次方幂；\n如果执行的是收缩操作，那么ht[1]的大小为第一个大于等于ht[0].used的2的n次方幂。\n\n\n在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。\n\n在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值增一。\n\n随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。\n\n当ht[0]包含的所有键值对都迁移到了ht[1]之后（ht[0]变为空表），释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表，为下一次rehash做准备。\n\n\n这种渐进式rehash的好处在于它采取分而治之的方式，将rehash键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量。\n缺点是因为同时有两张表保存数据，数据访问操作可能需要进行两次才能完成。\n总结字典被广泛用于实现Redis的各种功能，其中包括数据库和哈希键。本文介绍了Redis字典的底层实现，包括如何计算索引，解决键冲突和rehash。渐进式的rehash让我印象最深，这种大而化小的解决思路值得学习。\n","slug":"redis3","date":"2021-03-09T05:11:45.000Z","categories_index":"学习笔记,Redis","tags_index":"Redis数据结构与对象","author_index":"年鲤"},{"id":"46dc18036d332e4e6512d9692f74910b","title":"Redis（二）：链表","content":"\n\n链表被广泛用于实现Redis的各种功能，比如列表键、发布与订阅、慢查询、监视器等。直接看结构示意图：\n\n特征总结如下：\n双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的复杂度都是O（1）。\n无环：表头节点的prev指针和表尾节点的next指针都指向NULL，对链表的访问以NULL为终点。\n带表头指针和表尾指针：通过list结构的head指针和tail指针，程序获取链表的表头节点和表尾节点的复杂度为O（1）。\n带链表长度计数器：程序使用list结构的len属性来对list持有的链表节点进行计数，程序获取链表中节点数量的复杂度为O（1）。\n多态：链表节点使用void*指针来保存节点值，并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。\ndup函数用于复制链表节点所保存的值；\nfree函数用于释放链表节点所保存的值；\nmatch函数则用于对比链表节点所保存的值和另一个输入值是否相等。\n\n\n\n总结链表在数据结构中相当经典实用。\n","slug":"redis2","date":"2021-03-09T04:13:45.000Z","categories_index":"学习笔记,Redis","tags_index":"Redis数据结构与对象","author_index":"年鲤"},{"id":"f3d0b05742076b1a6be5180a2d1e28f1","title":"Redis（一）：SDS","content":"\n\nRedis 是 C 语言实现的，但是 Redis 放弃了 C 语言传统的字符串而是自己创建了一种名为}简单动态字符串 SDS（Simple Dynamic String）的抽象类型，并将 SDS 用作 Redis 的默认字符串表示，其主要原因就是传统的字符串表示方式并不能满足 Redis 对字符串在安全性、效率、以及功能方面的要求。先来看看SDS长什么样吧\nSDS 数据结构示意图：\n可以看到字符串&quot;redis&quot;以字符数组的形式存放在了buf中，空字符&#39;\\0&#39;表示字符串结尾，这一点和C语言的字符串是一样的。而多出来的len，alloc，flags让SDS更安全、性能更好、功能性更强，具体来说就是：\n\n可以常数复杂度获取字符串长度。\n杜绝缓冲区溢出。\n减少修改字符串长度时所需的内存重分配次数。\n二进制安全。\n兼容部分C字符串函数。\n\n下面就来逐条分析SDS是怎么做到这几点的。\n一、 常数复杂度获取字符串长度C语言字符串没有记录自身的长度信息，所以要获取字符串长度时，就要从头开始挨个读字符，直到读取到意味着结尾的空字符&#39;\\0&#39;, 复杂度为**O(n)。而SDS把长度信息记录在了len字段，需要获取字符串长度时直接读len的值就OK了，复杂度降到了O(1)**。\n二、 杜绝缓冲区溢出缓冲区溢出（buffer overflow）是指当程序将数据写入缓冲区并且数据过长时，会超过缓冲区的边界，并覆盖相邻的内存位置而造成的异常。C字符串会有缓冲区溢出的风险同样是因为没有记录自身长度，不会自动进行边界检查。而SDS就不会粗暴地把大象塞进冰箱。\n当SDS要进行修改时，Redis首先会检查SDS的空间是否满足修改所需的要求，如果不满足的话，就会自动将SDS的空间扩展至执行修改所需的大小，然后才执行实际的修改操作。\n三、减小修改字符串长度时所需的内存重分配次数上一节提到SDS会视情况扩展空间，这涉及到了重新分配内存，然而频繁分配内存会显著影响性能，这可不行。SDS通过空间预分配和惰性空间释放两种优化策略减小修改字符串长度时所需的内存重分配次数。\n1）空间预分配空间预分配用于优化SDS的字符串增长操作，如果对SDS进行修改之后，SDS的长度（也即是len的值）将小于1MB，那么程序分配和len属性同样大小的未使用空间（结构图中的sdsavail）。\nalloc = len * 2\n而当SDS的长度将大于等于1MB，那么程序会直接分配1MB的未使用空间，避免浪费。\nalloc = len + 1MB\n这样的话当字符串增长的长度没有超过未使用的空间，就可以直接进行修改而不用重新分配内存了。注意，由于空字符&#39;\\0&#39;也占一字节长度，buf的实际长度为alloc + 1。\n2）惰性空间释放惰性空间释放用于优化SDS的字符串缩短操作，当需要缩短SDS保存的字符串时，Redis并不立即使用内存重分配来回收缩短后多出来的字节。多出来的长度被记录到alloc，等待被使用或在合适的时机释放。\n二进制安全C字符串中的字符必须符合某种编码（比如ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得C字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据。\n使用SDS来保存之前提到的特殊数据格式就没有任何问题，因为SDS使用len属性的值而不是空字符来判断字符串是否结束。\n那么SDS为什么还要遵循以空字符结尾的规则呢？\n兼容部分C字符串函数因为SDS遵循C字符串以空字符结尾的惯例：数据的末尾设置为空字符，并且总会在为buf数组分配空间时多分配一个字节来容纳这个空字符，所以的SDS可以重用一部分&lt;string.h&gt;库定义的函数。这样避免了重复造轮子，去实现字符串对比之类的函数了。\n总结C字符串虽然简单高效，但是在特定情况下也存在安全和性能问题。Redis通过封装SDS解决了这些问题。分析Redis解决这些问题的方法，也可以获取一定的启发，比如针对应用场景做优化，适当预留资源，在不破坏整体功能的情况遵循惯例来提高兼容性。\n","slug":"redis1","date":"2021-03-05T08:24:45.000Z","categories_index":"学习笔记,Redis","tags_index":"Redis数据结构与对象","author_index":"年鲤"}]